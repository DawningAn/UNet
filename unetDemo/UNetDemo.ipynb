{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# 构建UNet网络"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"unet.png\" width=\"1200\">"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# 两次卷积操作\n",
    "class ConvBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.step = torch.nn.Sequential(\n",
    "            # 第一次卷积 (不改变大小，只改变输出通道数)\n",
    "            torch.nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1, stride=1),\n",
    "            #ReLU\n",
    "            torch.nn.ReLU(),\n",
    "            # 第二次卷积 (不改变大小，不改变输出通道数)\n",
    "            torch.nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, padding=1, stride=1),\n",
    "            #ReLU\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.step(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# 模块初始化\n",
    "conv_block = ConvBlock(1, 64).to('cuda:0')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]             640\n",
      "              ReLU-2         [-1, 64, 256, 256]               0\n",
      "            Conv2d-3         [-1, 64, 256, 256]          36,928\n",
      "              ReLU-4         [-1, 64, 256, 256]               0\n",
      "================================================================\n",
      "Total params: 37,568\n",
      "Trainable params: 37,568\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 128.00\n",
      "Params size (MB): 0.14\n",
      "Estimated Total Size (MB): 128.39\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 查看输出大小\n",
    "summary(conv_block, (1, 256, 256))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# 定义网络架构 (下采样：最大池化 上采样：双线性插值 特征融合：)\n",
    "class UNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 定义左半部分\n",
    "        self.layer1 = ConvBlock(1, 64)\n",
    "        self.layer2 = ConvBlock(64, 128)\n",
    "        self.layer3 = ConvBlock(128, 256)\n",
    "        self.layer4 = ConvBlock(256, 512)\n",
    "\n",
    "        # 定义右半部分\n",
    "        self.layer5 = ConvBlock(256 + 512, 256)\n",
    "        self.layer6 = ConvBlock(128 + 256, 128)\n",
    "        self.layer7 = ConvBlock(64 + 128, 64)\n",
    "\n",
    "        # 最后一个卷积\n",
    "        self.layer8 = torch.nn.Conv2d(in_channels=64, out_channels=1, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        #池化\n",
    "        self.Maxpool = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        # 上采样 -- scale_factor:放大倍数\n",
    "        self.UpSample = torch.nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "\n",
    "        #sigmoid\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 对输入数据 x进行处理 (下采样)\n",
    "        # input:(1*256*256) output:(64*256*256)\n",
    "        x1 = self.layer1(x)\n",
    "        # 池化\n",
    "        # input:(64*256*256) output:(64*128*128)\n",
    "        x1_mp = self.Maxpool(x1)\n",
    "\n",
    "        # input:(64*128*128) output:(128*128*128)\n",
    "        x2 = self.layer2(x1_mp)\n",
    "        # input:(128*128*128) output:(128*64*64)\n",
    "        x2_mp = self.Maxpool(x2)\n",
    "\n",
    "        # input:(128*64*64) output:(256*64*64)\n",
    "        x3 = self.layer3(x2_mp)\n",
    "        # input:(256*64*64) output:(256*32*32)\n",
    "        x3_mp = self.Maxpool(x3)\n",
    "\n",
    "        # input:(256*32*32) output:(512*32*32)\n",
    "        x4 = self.layer4(x3_mp)\n",
    "\n",
    "        # 上采样部分\n",
    "        # input:(512*32*32) output:(512*64*64)\n",
    "        x5 = self.UpSample(x4)\n",
    "        # 特征拼接 x3 和 x5\n",
    "        x5 = torch.cat([x5, x3], dim=1)  # 在通道维度上拼接   output:(768*64*64)\n",
    "        # 卷积 intput:(768*64*64)  output:(256*64*64)\n",
    "        x5 = self.layer5(x5)\n",
    "\n",
    "        # intput:(256*64*64)  output:(256*128*128)\n",
    "        x6 = self.UpSample(x5)\n",
    "        # 拼接 在通道维度上拼接 output:(384,128,128)\n",
    "        x6 = torch.cat([x6, x2], dim=1)\n",
    "        # 卷积 intput:(384*128*128)  output:(128*128*128)\n",
    "        x6 = self.layer6(x6)\n",
    "\n",
    "        # intput:(128*128*128) output:(128*256*256)\n",
    "        x7 = self.UpSample(x6)\n",
    "        # 拼接 在通道维度上拼接 output:(64+ 128*256*256)\n",
    "        x7 = torch.cat([x7, x1], dim=1)\n",
    "        # 卷积 input:(192*256*256) output:(64*256*256)\n",
    "        x7 = self.layer7(x7)\n",
    "\n",
    "        # 最后一次卷积\n",
    "        # input:(64*256*256) output:(1*256*256)\n",
    "        x8 = self.layer8(x7)\n",
    "\n",
    "        #sigmoid\n",
    "        x9 = self.sigmoid(x8)\n",
    "\n",
    "        return x9"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# unet实例化\n",
    "unet = UNet().to('cuda:0')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]             640\n",
      "              ReLU-2         [-1, 64, 256, 256]               0\n",
      "            Conv2d-3         [-1, 64, 256, 256]          36,928\n",
      "              ReLU-4         [-1, 64, 256, 256]               0\n",
      "         ConvBlock-5         [-1, 64, 256, 256]               0\n",
      "         MaxPool2d-6         [-1, 64, 128, 128]               0\n",
      "            Conv2d-7        [-1, 128, 128, 128]          73,856\n",
      "              ReLU-8        [-1, 128, 128, 128]               0\n",
      "            Conv2d-9        [-1, 128, 128, 128]         147,584\n",
      "             ReLU-10        [-1, 128, 128, 128]               0\n",
      "        ConvBlock-11        [-1, 128, 128, 128]               0\n",
      "        MaxPool2d-12          [-1, 128, 64, 64]               0\n",
      "           Conv2d-13          [-1, 256, 64, 64]         295,168\n",
      "             ReLU-14          [-1, 256, 64, 64]               0\n",
      "           Conv2d-15          [-1, 256, 64, 64]         590,080\n",
      "             ReLU-16          [-1, 256, 64, 64]               0\n",
      "        ConvBlock-17          [-1, 256, 64, 64]               0\n",
      "        MaxPool2d-18          [-1, 256, 32, 32]               0\n",
      "           Conv2d-19          [-1, 512, 32, 32]       1,180,160\n",
      "             ReLU-20          [-1, 512, 32, 32]               0\n",
      "           Conv2d-21          [-1, 512, 32, 32]       2,359,808\n",
      "             ReLU-22          [-1, 512, 32, 32]               0\n",
      "        ConvBlock-23          [-1, 512, 32, 32]               0\n",
      "         Upsample-24          [-1, 512, 64, 64]               0\n",
      "           Conv2d-25          [-1, 256, 64, 64]       1,769,728\n",
      "             ReLU-26          [-1, 256, 64, 64]               0\n",
      "           Conv2d-27          [-1, 256, 64, 64]         590,080\n",
      "             ReLU-28          [-1, 256, 64, 64]               0\n",
      "        ConvBlock-29          [-1, 256, 64, 64]               0\n",
      "         Upsample-30        [-1, 256, 128, 128]               0\n",
      "           Conv2d-31        [-1, 128, 128, 128]         442,496\n",
      "             ReLU-32        [-1, 128, 128, 128]               0\n",
      "           Conv2d-33        [-1, 128, 128, 128]         147,584\n",
      "             ReLU-34        [-1, 128, 128, 128]               0\n",
      "        ConvBlock-35        [-1, 128, 128, 128]               0\n",
      "         Upsample-36        [-1, 128, 256, 256]               0\n",
      "           Conv2d-37         [-1, 64, 256, 256]         110,656\n",
      "             ReLU-38         [-1, 64, 256, 256]               0\n",
      "           Conv2d-39         [-1, 64, 256, 256]          36,928\n",
      "             ReLU-40         [-1, 64, 256, 256]               0\n",
      "        ConvBlock-41         [-1, 64, 256, 256]               0\n",
      "           Conv2d-42          [-1, 1, 256, 256]              65\n",
      "          Sigmoid-43          [-1, 1, 256, 256]               0\n",
      "================================================================\n",
      "Total params: 7,781,761\n",
      "Trainable params: 7,781,761\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 707.00\n",
      "Params size (MB): 29.69\n",
      "Estimated Total Size (MB): 736.94\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(unet,(1,256,256))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
